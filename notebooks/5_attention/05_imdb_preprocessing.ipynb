{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tokenizers as tk\n",
    "import mltrainer\n",
    "mltrainer.__version__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the IMDB dataset. This is the MNIST for language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "imdbdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.IMDB)\n",
    "datasets = imdbdatasetfactory.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = datasets[\"train\"]\n",
    "testdataset = datasets[\"valid\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists of 50k movie reviews, labeled positive or negative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's have a look at the first datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = traindataset[10]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in traindataset:\n",
    "    if \"<br\" in x:\n",
    "        print(x)\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is messy data. We have Uppercase, punctuation, and even html tags. Let's clean some of that in order to reduce dimensionality, without loosing too much information about the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"I'd like to think myself as a fairly open minded guy and it takes a lot(!) for me to dislike a movie but this one is without a doubt one of the suckiest, crappiest movie I've ever seen!<br />From the decrepit ranks of the already over-saturated \\'Hillybilly Horror\\'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.normalizers import Lowercase, StripAccents, Sequence, NFD, Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Sequence([NFD(), Replace(\"<br />\", \"\"), StripAccents(), Lowercase()])\n",
    "normalizer.normalize_str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE())\n",
    "trainer = BpeTrainer(special_tokens=[\"<unk>\"])\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.normalizer = normalizer\n",
    "tokenizer.train_from_iterator(traindataset, trainer=trainer)\n",
    "print(f\"the vocab size is {tokenizer.get_vocab_size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maps a sentence of words to a sequence of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(test).ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can create a tensor with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.tensor(tokenizer.encode(test).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional, Callable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(\n",
    "        self, max: int, tokenizer\n",
    "    ) -> None:\n",
    "        self.max = max\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        if label == \"neg\":\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def __call__(self, batch: List) -> Tuple[Tensor, Tensor]:\n",
    "        labels, text = [], []\n",
    "        for x, y in batch:\n",
    "            tokens = torch.tensor(self.tokenizer.encode(x).ids)\n",
    "            tokens = tokens[:self.max]\n",
    "            text.append(tokens)\n",
    "            labels.append(self.cast_label(y))\n",
    "\n",
    "        text_ = pad_sequence(text, batch_first=True, padding_value=0)\n",
    "        return text_, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [(\"The cat sat on the mat\", \"neg\"), (\"Where is the cat?\", \"pos\"), (\"The cat is blas√©\", \"neg\")]\n",
    "pp = Preprocessor(max = 5, tokenizer=tokenizer)\n",
    "pp(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is necessary to:\n",
    "- cut of long sentences to get equal length. 100 words will be enough to get the sentiment in most cases\n",
    "- we need to cast the labels \"neg\" and \"pos\" to integers\n",
    "- we also pad if a sentence is shorter than the max lenght\n",
    "\n",
    "We can feed the preprocessor to the default dataloader from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "preprocessor = Preprocessor(max=512, tokenizer=tokenizer)\n",
    "dataloader = DataLoader(\n",
    "    traindataset, collate_fn=preprocessor, batch_size=32, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get batched sentences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this code is wrapped into the DatasetFactoryProvider, which you can see in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
